{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "\n",
    "데이터가 항상 머신러닝 알고리즘을 훈련하는 데 적합한 최종 처리된 형태로 제공되는 것은 아닙니다. **Transforms**을 사용하여 데이터를 일부 조작하고 학습에 적합하게 만듭니다.\n",
    "\n",
    "모든 TorchVision의 데이터셋에는 변환 논리(transformation logic)가 포함된 호출을 허용하는 두 개의 파라미터(Feature를 수정하는 `transform` / 레이블을 수정하는 `target_transform`)가 있습니다.\n",
    "[torchvision.transforms](https://pytorch.org/vision/stable/transforms.html) 모듈은 일반적으로 사용되는 몇 가지 transform을 제공합니다.\n",
    "\n",
    "Fashion MNIST의 Feature는 PIL 이미지 형식이며 레이블은 정수(integers)입니다. 훈련을 위해서는 정규화된 Tensor로서의 Feature와 One-Hot Encoding 된 레이블이 필요합니다. 이러한 변환을 수행하기 위해 `ToTensor` 및 `Lambda`를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToTensor()\n",
    "\n",
    "[ToTensor](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor)는 PIL 이미지 또는 Numpy의 `ndarray`를 `FloatTensor`로 변환하고, \\[0., 1.\\] 범위에서 이미지의 픽셀 값을 조정합니다.\n",
    "\n",
    "\n",
    "## Lambda transforms\n",
    "\n",
    "람다(Lambda) 변환은 사용자 정의 람다 함수를 적용합니다. 여기서는 정수를 One-Hot Encoding Tensor로 변환하는 함수를 정의합니다. 먼저 크기가 10인 Zero Tensor를 레이블 수 만큼 만들고, [scatter](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.scatter_)를 이용하여 레이블 `y`에 지정된 대로 인덱스에 `value=1`을 할당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transform = Lambda(lambda y: torch.zeros(\n",
    "    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "conda-env-py37_pytorch-py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
