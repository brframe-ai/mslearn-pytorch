{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 음성 모델 구축하기\n",
    "\n",
    "이제 우리는 음성 데이터를 스펙트로그램 이미지를 만들었으니 컴퓨터 비전 모델을 구축해야 합니다. 학습 경로를 따르고 있다면 이미 경로의 두 번째 모듈에서 컴퓨터 비전 모델을 만들었습니다. \n",
    "비전 모델을 구축하기 위해 [vision](https://pypi.org/project/torchvision/) 패키지를 사용해야하 합니다. 모델을 구축하는 데 필요한 패키지를 가져오도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습을 위해 DataLoader에 Spectrogram 이미지 불러오기\n",
    "\n",
    "여기서는 이미지 데이터의 경로를 제공하고 `ImageFolder` helper를 사용하여 이미지를 텐서로 불러 옵니다. 라벨은 폴더 이름을 기준으로 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 7985\n",
      "    Root location: ./data/spectrograms\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(201, 81), interpolation=PIL.Image.BILINEAR)\n",
      "               ToTensor()\n",
      "           )\n",
      "torch.Size([3, 201, 81])\n"
     ]
    }
   ],
   "source": [
    "data_path = './data/spectrograms' #looking in subfolder train\n",
    "\n",
    "yes_no_dataset = datasets.ImageFolder(\n",
    "    root=data_path,\n",
    "    transform=transforms.Compose([transforms.Resize((201,81)),\n",
    "                                  transforms.ToTensor()\n",
    "                                  ])\n",
    ")\n",
    "print(yes_no_dataset)\n",
    "print(yes_no_dataset[5][0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 및 테스트를 위해 데이터 분할\n",
    "\n",
    "- 데이터를 분할하여 train, test set을 8:2로 나눕니다. 모델 학습에 80 %를 사용하고 모델 성능를 평가하는데 20 %를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6388\n",
      "1597\n"
     ]
    }
   ],
   "source": [
    "#split data to test and train\n",
    "#use 80% to train\n",
    "train_size = int(0.8 * len(yes_no_dataset))\n",
    "test_size = len(yes_no_dataset) - train_size\n",
    "yes_no_train_dataset, yes_no_test_dataset = torch.utils.data.random_split(yes_no_dataset, [train_size, test_size])\n",
    "\n",
    "print(len(yes_no_train_dataset))\n",
    "print(len(yes_no_test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `DataLoader`로 trian, test 데이터셋을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    yes_no_train_dataset,\n",
    "    batch_size=15,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    yes_no_test_dataset,\n",
    "    batch_size=15,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataLoader로 읽은 데이터셋의 텐서 형태를 살펴봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5608, 0.4824, 0.5098, 0.4353, 0.3490, 0.4824, 0.5843, 0.4392, 0.4667,\n",
       "        0.3608, 0.4431, 0.5059, 0.4667, 0.4824, 0.4745, 0.4118, 0.4431, 0.2039,\n",
       "        0.4510, 0.3765, 0.3804, 0.4118, 0.4745, 0.4706, 0.4392, 0.5020, 0.5020,\n",
       "        0.5137, 0.5059, 0.3922, 0.3059, 0.3804, 0.4196, 0.3647, 0.3647, 0.4392,\n",
       "        0.3451, 0.3804, 0.3608, 0.4078, 0.6392, 0.6980, 0.7529, 0.5333, 0.7137,\n",
       "        0.8000, 0.5882, 0.6196, 0.7373, 0.6863, 0.6863, 0.6118, 0.5922, 0.4863,\n",
       "        0.5725, 0.5608, 0.5098, 0.4745, 0.4745, 0.4431, 0.4706, 0.4000, 0.4039,\n",
       "        0.4314, 0.4275, 0.3333, 0.1569, 0.4353, 0.4824, 0.4588, 0.4118, 0.3961,\n",
       "        0.4314, 0.4118, 0.2667, 0.3686, 0.4980, 0.4941, 0.4275, 0.4863, 0.5922])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset[0][0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 학습을 위해 GPU를 가져오거나 GPU를 사용할 수 없는 경우 CPU를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 생성하기\n",
    "- CNN(convolution neural network)을 만들고 장치(GPU or CPU)를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNet(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (flatten): Flatten()\n",
      "  (fc1): Linear(in_features=51136, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(51136, 50)\n",
    "        self.fc2 = nn.Linear(50, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x,dim=1)\n",
    "    \n",
    "model = CNNet().to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습과 테스트 관련 함수 생성\n",
    "- 여기서는 비용 함수(cost function),  learning_rate 및 optimizer을 설정합니다. 그런 다음 사용할 train, test 함수를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function used to determine best parameters\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# used to create optimal parameters\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create the training function\n",
    "\n",
    "def train(dataloader, model, loss, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = cost(pred, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "\n",
    "# Create the validation/test function\n",
    "\n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, Y) in enumerate(dataloader):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += cost(pred, Y).item()\n",
    "            correct += (pred.argmax(1)==Y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "\n",
    "    print(f'\\nTest Error:\\nacc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습하기\n",
    "- 이제 epoch 수를 설정하고 epoch 마다 `train`과 `test`함수를 호출하도록 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.683419  [    0/ 6388]\n",
      "loss: 0.695789  [ 1500/ 6388]\n",
      "loss: 0.692987  [ 3000/ 6388]\n",
      "loss: 0.666870  [ 4500/ 6388]\n",
      "loss: 0.692348  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 49.7%, avg loss: 0.046441\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 6388]\n",
      "loss: 0.693147  [ 1500/ 6388]\n",
      "loss: 0.693147  [ 3000/ 6388]\n",
      "loss: 0.693147  [ 4500/ 6388]\n",
      "loss: 0.723022  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 49.7%, avg loss: 0.046441\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 6388]\n",
      "loss: 0.666938  [ 1500/ 6388]\n",
      "loss: 0.773418  [ 3000/ 6388]\n",
      "loss: 0.666485  [ 4500/ 6388]\n",
      "loss: 0.685241  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 49.7%, avg loss: 0.046441\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.695083  [    0/ 6388]\n",
      "loss: 0.706812  [ 1500/ 6388]\n",
      "loss: 0.620915  [ 3000/ 6388]\n",
      "loss: 0.488353  [ 4500/ 6388]\n",
      "loss: 0.471648  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 86.9%, avg loss: 0.022696\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.271708  [    0/ 6388]\n",
      "loss: 0.274831  [ 1500/ 6388]\n",
      "loss: 0.166102  [ 3000/ 6388]\n",
      "loss: 0.617657  [ 4500/ 6388]\n",
      "loss: 0.122830  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 89.7%, avg loss: 0.016228\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.347690  [    0/ 6388]\n",
      "loss: 0.256594  [ 1500/ 6388]\n",
      "loss: 0.358795  [ 3000/ 6388]\n",
      "loss: 0.380411  [ 4500/ 6388]\n",
      "loss: 0.844688  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 90.8%, avg loss: 0.014417\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.339621  [    0/ 6388]\n",
      "loss: 0.173808  [ 1500/ 6388]\n",
      "loss: 0.449916  [ 3000/ 6388]\n",
      "loss: 0.249338  [ 4500/ 6388]\n",
      "loss: 0.115090  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 92.3%, avg loss: 0.012824\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.199789  [    0/ 6388]\n",
      "loss: 0.266175  [ 1500/ 6388]\n",
      "loss: 0.135942  [ 3000/ 6388]\n",
      "loss: 0.120991  [ 4500/ 6388]\n",
      "loss: 0.436009  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 92.8%, avg loss: 0.012056\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.520262  [    0/ 6388]\n",
      "loss: 0.126356  [ 1500/ 6388]\n",
      "loss: 0.225927  [ 3000/ 6388]\n",
      "loss: 0.128359  [ 4500/ 6388]\n",
      "loss: 0.157707  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 93.1%, avg loss: 0.011095\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.074408  [    0/ 6388]\n",
      "loss: 0.227902  [ 1500/ 6388]\n",
      "loss: 0.094457  [ 3000/ 6388]\n",
      "loss: 0.229964  [ 4500/ 6388]\n",
      "loss: 0.205378  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 93.6%, avg loss: 0.010279\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.193544  [    0/ 6388]\n",
      "loss: 0.209379  [ 1500/ 6388]\n",
      "loss: 0.170117  [ 3000/ 6388]\n",
      "loss: 0.366720  [ 4500/ 6388]\n",
      "loss: 0.118462  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 93.6%, avg loss: 0.010135\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.146690  [    0/ 6388]\n",
      "loss: 0.123937  [ 1500/ 6388]\n",
      "loss: 0.150614  [ 3000/ 6388]\n",
      "loss: 0.052775  [ 4500/ 6388]\n",
      "loss: 0.131337  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 94.0%, avg loss: 0.009229\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.155237  [    0/ 6388]\n",
      "loss: 0.051295  [ 1500/ 6388]\n",
      "loss: 0.274036  [ 3000/ 6388]\n",
      "loss: 0.062302  [ 4500/ 6388]\n",
      "loss: 0.116733  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 94.5%, avg loss: 0.009083\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.244489  [    0/ 6388]\n",
      "loss: 0.084151  [ 1500/ 6388]\n",
      "loss: 0.180910  [ 3000/ 6388]\n",
      "loss: 0.147533  [ 4500/ 6388]\n",
      "loss: 0.064108  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 94.8%, avg loss: 0.008690\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.236073  [    0/ 6388]\n",
      "loss: 0.030132  [ 1500/ 6388]\n",
      "loss: 0.263236  [ 3000/ 6388]\n",
      "loss: 0.107276  [ 4500/ 6388]\n",
      "loss: 0.104241  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 94.6%, avg loss: 0.008002\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------------------')\n",
    "    train(train_dataloader, model, cost, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가 하기\n",
    "\n",
    "좋은 결과 입니다! 15번째 EPOCH까지는 93%-95%의 정확도를 얻었어야 합니다. 여기서는 테스트 데이터 세트의 결과를 가져와서 예측 라벨과 실제 라벨을 보고 모델의 성능이 어느정도 인지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Actual:\n",
      "tensor([1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, (X, Y) in enumerate(test_dataloader):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        pred = model(X)\n",
    "        print(\"Predicted:\")\n",
    "        print(f\"{pred.argmax(1)}\")\n",
    "        print(\"Actual:\")\n",
    "        print(f\"{Y}\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
